{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/penguix0/container-detection/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fOv8pjdBsYj"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIyMivGzB0O4",
        "outputId": "d751f4ea-e6e3-4f8e-a76b-28c61e3cd805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (3.19.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (2.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.15.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (5.10.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (2.23.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.3.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (4.64.1)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (4.1.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->tensorflow-datasets) (3.10.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.56.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install pillow\n",
        "!pip install tensorflow-datasets\n",
        "!pip install numpy\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQUcXbv4Cinb"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKNLnCYdCmf6"
      },
      "source": [
        "Import all libraries needed and configure the dataset and logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zIV1bjLACr1Z"
      },
      "outputs": [],
      "source": [
        "## Import libaries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Import the dataset\n",
        "import container_dataset\n",
        "\n",
        "# Setup logging\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BnV-SjqDX8c"
      },
      "source": [
        "## Import and test the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTLoSqlnDbW_",
        "outputId": "0a0cc50f-be31-4192-b56b-1c50db4ad8e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class names: ['container_front']\n",
            "Number of training examples: 85\n",
            "Number of test examples:     10\n"
          ]
        }
      ],
      "source": [
        "## Load the dataset\n",
        "(train_dataset, val_dataset, test_dataset), metadata = tfds.load(\"container_dataset\", \n",
        "    split=[\"train[:80%]\", \"train[80%:]\", \"test\"], \n",
        "    with_info=True)\n",
        "\n",
        "## Print classes which the program can detect\n",
        "class_names = metadata.features['objects'][\"label\"].names\n",
        "print(\"Class names: {}\".format(class_names))\n",
        "\n",
        "## Print the number of examples in each set\n",
        "num_train_examples = metadata.splits['train'].num_examples\n",
        "num_test_examples = metadata.splits['test'].num_examples\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of test examples:     {}\".format(num_test_examples))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract all data from datset"
      ],
      "metadata": {
        "id": "dIdJsPQ1UR5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH = 100 #pixels\n",
        "IMG_HEIGHT = 100 #pixels\n",
        "IMG_DEPTH = 3\n",
        "\n",
        "train_dataset_img = []\n",
        "train_dataset_objects = []\n",
        "## Prepare all images\n",
        "for i in iter(train_dataset):\n",
        "    img = i[\"image\"]\n",
        "    train_dataset_img.append(img)\n",
        "    objects = []\n",
        "    for feature in i[\"objects\"]:\n",
        "        objects.append(i[\"objects\"][feature])\n",
        "    train_dataset_objects.append(objects)\n",
        "\n",
        "test_dataset_img = []\n",
        "test_dataset_objects = []\n",
        "## Prepare all images\n",
        "for i in iter(test_dataset):\n",
        "    img = i[\"image\"]\n",
        "    test_dataset_img.append(img)\n",
        "    objects = []\n",
        "    for feature in i[\"objects\"]:\n",
        "        objects.append(i[\"objects\"][feature])\n",
        "\n",
        "    test_dataset_objects.append(objects)\n",
        "\n",
        "val_dataset_img = []\n",
        "val_dataset_objects = []\n",
        "## Prepare all images\n",
        "for i in iter(val_dataset):\n",
        "    img = i[\"image\"]\n",
        "    val_dataset_img.append(img)\n",
        "    objects = []\n",
        "    for feature in i[\"objects\"]:\n",
        "        objects.append(i[\"objects\"][feature])\n",
        "    val_dataset_objects.append(objects)\n",
        "\n",
        "train_image_generator      = ImageDataGenerator(rescale=1./255)  # Generator for our training data\n",
        "test_image_generator       = ImageDataGenerator(rescale=1./255)  # Generator for our test data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)  # Generator for our validation data\n",
        "\n"
      ],
      "metadata": {
        "id": "htPMLMIrUYng"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create flows from data"
      ],
      "metadata": {
        "id": "BkfOmr8uUfW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 5 # Number of training examples to process before updating our models variables\n",
        "print (len(train_dataset_img))\n",
        "print (train_dataset_img[0])\n",
        "\n",
        "train_data_gen = train_image_generator.flow(x=np.asarray(train_dataset_img).astype('float64'),\n",
        "                                            y=train_dataset_objects,\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            shuffle=True)\n",
        "\n",
        "test_data_gen = validation_image_generator.flow(x=np.asarray(test_dataset_img).astype('float64'),\n",
        "                                               y=test_dataset_objects,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=False)\n",
        "\n",
        "val_data_gen = validation_image_generator.flow(x=np.asarray(val_dataset_img).astype('float64'),\n",
        "                                               y=val_dataset_objects,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9cV-PUTUg1G",
        "outputId": "d895efe6-0140-4db7-ab8a-3a6771924c99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68\n",
            "tf.Tensor(\n",
            "[[[246 255 251]\n",
            "  [243 252 247]\n",
            "  [245 249 248]\n",
            "  ...\n",
            "  [252 252 250]\n",
            "  [252 252 250]\n",
            "  [252 252 250]]\n",
            "\n",
            " [[250 241 246]\n",
            "  [255 252 253]\n",
            "  [255 255 253]\n",
            "  ...\n",
            "  [252 252 250]\n",
            "  [252 252 250]\n",
            "  [252 252 250]]\n",
            "\n",
            " [[255 250 248]\n",
            "  [255 251 249]\n",
            "  [252 248 245]\n",
            "  ...\n",
            "  [252 252 250]\n",
            "  [252 252 250]\n",
            "  [252 252 250]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 99 108 105]\n",
            "  [ 88  97  96]\n",
            "  [ 77  87  86]\n",
            "  ...\n",
            "  [196 193 188]\n",
            "  [191 188 183]\n",
            "  [191 188 183]]\n",
            "\n",
            " [[156 156 154]\n",
            "  [143 143 143]\n",
            "  [127 129 128]\n",
            "  ...\n",
            "  [194 191 186]\n",
            "  [190 187 182]\n",
            "  [190 187 182]]\n",
            "\n",
            " [[164 163 159]\n",
            "  [159 158 156]\n",
            "  [156 155 153]\n",
            "  ...\n",
            "  [189 186 181]\n",
            "  [184 181 176]\n",
            "  [186 183 178]]], shape=(100, 100, 3), dtype=uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py:689: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.y = np.asarray(y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and compile a model"
      ],
      "metadata": {
        "id": "ZxInNUwUUinE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_DEPTH)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(4)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cNHeV43QUmCY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "OO0L1OKcUob3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 14\n",
        "\n",
        "history = model.fit(\n",
        "    tf.convert_to_tensor(train_data_gen),\n",
        "    steps_per_epoch=int(np.ceil(len(train_dataset_img) / float(BATCH_SIZE))),\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "metadata": {
        "id": "cOEof8nzUrMP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1PBZRWartoVj-34PCTHuZjh_6es29tHDJ",
      "authorship_tag": "ABX9TyMx+iLcVT1uytrW8k4WuKjd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}